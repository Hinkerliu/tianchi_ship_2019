{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_feature(df, key, target, aggs):   \n",
    "    agg_dict = {}\n",
    "    for ag in aggs:\n",
    "        agg_dict[f'{target}_{ag}'] = ag\n",
    "    print(agg_dict)\n",
    "    t = df.groupby(key)[target].agg(agg_dict).reset_index()\n",
    "    return t\n",
    "\n",
    "def extract_feature(df, train):\n",
    "    t = group_feature(df, 'ship','x',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','x',['count'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','y',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','v',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','d',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    train['x_max_x_min'] = train['x_max'] - train['x_min']\n",
    "    train['y_max_y_min'] = train['y_max'] - train['y_min']\n",
    "    train['y_max_x_min'] = train['y_max'] - train['x_min']\n",
    "    train['x_max_y_min'] = train['x_max'] - train['y_min']\n",
    "    train['slope'] = train['y_max_y_min'] / np.where(train['x_max_x_min']==0, 0.001, train['x_max_x_min'])\n",
    "    train['area'] = train['x_max_x_min'] * train['y_max_y_min']\n",
    "    \n",
    "    mode_hour = df.groupby('ship')['hour'].agg(lambda x:x.value_counts().index[0]).to_dict()\n",
    "    train['mode_hour'] = train['ship'].map(mode_hour)\n",
    "    \n",
    "    t = group_feature(df, 'ship','hour',['max','min'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    \n",
    "    hour_nunique = df.groupby('ship')['hour'].nunique().to_dict()\n",
    "    date_nunique = df.groupby('ship')['date'].nunique().to_dict()\n",
    "    train['hour_nunique'] = train['ship'].map(hour_nunique)\n",
    "    train['date_nunique'] = train['ship'].map(date_nunique)\n",
    "\n",
    "    t = df.groupby('ship')['time'].agg({'diff_time':lambda x:np.max(x)-np.min(x)}).reset_index()\n",
    "    t['diff_day'] = t['diff_time'].dt.days\n",
    "    t['diff_second'] = t['diff_time'].dt.seconds\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    return train\n",
    "\n",
    "def extract_dt(df):\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%m%d %H:%M:%S')\n",
    "    # df['month'] = df['time'].dt.month\n",
    "    # df['day'] = df['time'].dt.day\n",
    "    df['date'] = df['time'].dt.date\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    # df = df.drop_duplicates(['ship','month'])\n",
    "    df['weekday'] = df['time'].dt.weekday\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_hdf('./output/train.h5')\n",
    "# train = df.drop_duplicates(['ship','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_hdf('./output/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = extract_dt(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = extract_dt(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train.drop_duplicates('ship')\n",
    "test_label = test.drop_duplicates('ship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "拖网    0.623000\n",
       "围网    0.231571\n",
       "刺网    0.145429\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label['type'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_map = dict(zip(train_label['type'].unique(), np.arange(3)))\n",
    "type_map_rev = {v:k for k,v in type_map.items()}\n",
    "train_label['type'] = train_label['type'].map(type_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_max': 'max', 'x_min': 'min', 'x_mean': 'mean', 'x_std': 'std', 'x_skew': 'skew', 'x_sum': 'sum'}\n",
      "{'x_count': 'count'}\n",
      "{'y_max': 'max', 'y_min': 'min', 'y_mean': 'mean', 'y_std': 'std', 'y_skew': 'skew', 'y_sum': 'sum'}\n",
      "{'v_max': 'max', 'v_min': 'min', 'v_mean': 'mean', 'v_std': 'std', 'v_skew': 'skew', 'v_sum': 'sum'}\n",
      "{'d_max': 'max', 'd_min': 'min', 'd_mean': 'mean', 'd_std': 'std', 'd_skew': 'skew', 'd_sum': 'sum'}\n",
      "{'hour_max': 'max', 'hour_min': 'min'}\n"
     ]
    }
   ],
   "source": [
    "train_label = extract_feature(train, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_max': 'max', 'x_min': 'min', 'x_mean': 'mean', 'x_std': 'std', 'x_skew': 'skew', 'x_sum': 'sum'}\n",
      "{'x_count': 'count'}\n",
      "{'y_max': 'max', 'y_min': 'min', 'y_mean': 'mean', 'y_std': 'std', 'y_skew': 'skew', 'y_sum': 'sum'}\n",
      "{'v_max': 'max', 'v_min': 'min', 'v_mean': 'mean', 'v_std': 'std', 'v_skew': 'skew', 'v_sum': 'sum'}\n",
      "{'d_max': 'max', 'd_min': 'min', 'd_mean': 'mean', 'd_std': 'std', 'd_skew': 'skew', 'd_sum': 'sum'}\n",
      "{'hour_max': 'max', 'hour_min': 'min'}\n"
     ]
    }
   ],
   "source": [
    "test_label = extract_feature(test, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in train_label.columns if x not in ['ship','type','time','diff_time','date']]\n",
    "target = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 x,y,v,d,hour,weekday,x_max,x_min,x_mean,x_std,x_skew,x_sum,x_count,y_max,y_min,y_mean,y_std,y_skew,y_sum,v_max,v_min,v_mean,v_std,v_skew,v_sum,d_max,d_min,d_mean,d_std,d_skew,d_sum,x_max_x_min,y_max_y_min,y_max_x_min,x_max_y_min,slope,area,mode_hour,hour_max,hour_min,hour_nunique,date_nunique,diff_day,diff_second\n"
     ]
    }
   ],
   "source": [
    "print(len(features), ','.join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'early_stopping_rounds': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0766889\tvalid_1's multi_logloss: 0.274405\n",
      "[200]\ttraining's multi_logloss: 0.0190115\tvalid_1's multi_logloss: 0.279591\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's multi_logloss: 0.0404677\tvalid_1's multi_logloss: 0.272856\n",
      "0 val f1 0.8553343687425229\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0770786\tvalid_1's multi_logloss: 0.268496\n",
      "[200]\ttraining's multi_logloss: 0.0198795\tvalid_1's multi_logloss: 0.262743\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's multi_logloss: 0.0314965\tvalid_1's multi_logloss: 0.261853\n",
      "1 val f1 0.8556967144240627\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0821201\tvalid_1's multi_logloss: 0.280141\n",
      "[200]\ttraining's multi_logloss: 0.0214274\tvalid_1's multi_logloss: 0.269697\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's multi_logloss: 0.0256627\tvalid_1's multi_logloss: 0.268099\n",
      "2 val f1 0.8707176051755905\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0824696\tvalid_1's multi_logloss: 0.249233\n",
      "[200]\ttraining's multi_logloss: 0.0215951\tvalid_1's multi_logloss: 0.24171\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's multi_logloss: 0.0218734\tvalid_1's multi_logloss: 0.24151\n",
      "3 val f1 0.8833696688222153\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0753316\tvalid_1's multi_logloss: 0.324756\n",
      "[200]\ttraining's multi_logloss: 0.0180125\tvalid_1's multi_logloss: 0.330503\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's multi_logloss: 0.0451791\tvalid_1's multi_logloss: 0.32193\n",
      "4 val f1 0.8297545112441153\n"
     ]
    }
   ],
   "source": [
    "fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X = train_label[features].copy()\n",
    "y = train_label[target]\n",
    "models = []\n",
    "pred = np.zeros((len(test_label),3))\n",
    "oof = np.zeros((len(X), 3))\n",
    "for index, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n",
    "\n",
    "    train_set = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    val_set = lgb.Dataset(X.iloc[val_idx], y.iloc[val_idx])\n",
    "\n",
    "    model = lgb.train(params, train_set, valid_sets=[train_set, val_set], verbose_eval=100)\n",
    "    models.append(model)\n",
    "    val_pred = model.predict(X.iloc[val_idx])\n",
    "    oof[val_idx] = val_pred\n",
    "    val_y = y.iloc[val_idx]\n",
    "    val_pred = np.argmax(val_pred, axis=1)\n",
    "    print(index, 'val f1', metrics.f1_score(val_y, val_pred, average='macro'))\n",
    "    # 0.8695539641133697\n",
    "    # 0.8866211724839532\n",
    "\n",
    "    test_pred = model.predict(test_label[features])\n",
    "    pred += test_pred/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof f1 0.8589336249573334\n"
     ]
    }
   ],
   "source": [
    "oof = np.argmax(oof, axis=1)\n",
    "print('oof f1', metrics.f1_score(oof, y, average='macro'))\n",
    "# 0.8701544575329372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.6355\n",
      "1    0.2340\n",
      "2    0.1305\n",
      "Name: pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(pred, axis=1)\n",
    "sub = test_label[['ship']]\n",
    "sub['pred'] = pred\n",
    "\n",
    "print(sub['pred'].value_counts(1))\n",
    "sub['pred'] = sub['pred'].map(type_map_rev)\n",
    "sub.to_csv('result.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for index, model in enumerate(models):\n",
    "    df = pd.DataFrame()\n",
    "    df['name'] = model.feature_name()\n",
    "    df['score'] = model.feature_importance()\n",
    "    df['fold'] = index\n",
    "    ret.append(df)\n",
    "    \n",
    "df = pd.concat(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('name', as_index=False)['score'].mean()\n",
    "df = df.sort_values(['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hour</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hour_min</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hour_nunique</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>date_nunique</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>diff_day</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>diff_second</td>\n",
       "      <td>375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  score  fold\n",
       "0              x    510     0\n",
       "1              y    597     0\n",
       "2              v    332     0\n",
       "3              d    243     0\n",
       "4           hour     22     0\n",
       "..           ...    ...   ...\n",
       "39      hour_min      0     4\n",
       "40  hour_nunique      2     4\n",
       "41  date_nunique     10     4\n",
       "42      diff_day      0     4\n",
       "43   diff_second    375     4\n",
       "\n",
       "[220 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
